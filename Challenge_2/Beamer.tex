\documentclass[journal,12pt,twocolumn]{IEEEtran}

\usepackage{setspace}
\usepackage{gensymb}


\singlespacing

\usepackage[cmex10]{amsmath}
%\usepackage{amsthm}
%\interdisplaylinepenalty=2500
%\savesymbol{iint}
%\usepackage{txfonts}
%\restoresymbol{TXF}{iint}
%\usepackage{wasysym}
\usepackage{amsthm}

\usepackage{mathrsfs}
\usepackage{txfonts}
\usepackage{stfloats}
\usepackage{bm}
\usepackage{cite}
\usepackage{cases}
\usepackage{subfig}

\usepackage{longtable}
\usepackage{multirow}

\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{steinmetz}
\usepackage{tikz}
\usepackage{circuitikz}
\usepackage{verbatim}
\usepackage{tfrupee}
\usepackage[breaklinks=true]{hyperref}

\usepackage{tkz-euclide} %loads TikZ and tkz-base

\usetikzlibrary{calc,math}
\usepackage{listings}
    \usepackage{color}                                          
    \usepackage{array}                                          
    \usepackage{longtable}                                      
    \usepackage{calc}                                           
    \usepackage{multirow}                                       
    \usepackage{hhline}                                         
    \usepackage{ifthen}
    \usepackage{lscape}     
\usepackage{multicol}
\usepackage{chngcntr}

\DeclareMathOperator*{\Res}{Res}

\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}
\renewcommand\thesubsubsection{\thesubsection.\arabic{subsubsection}}

\renewcommand\thesectiondis{\arabic{section}}
\renewcommand\thesubsectiondis{\thesectiondis.\arabic{subsection}}
\renewcommand\thesubsubsectiondis{\thesubsectiondis.\arabic{subsubsection}}

\hyphenation{op-tical net-works semi-conduc-tor}
\def\inputGnumericTable{}                                 %%

\lstset{
%language=C,
frame=single, 
breaklines=true,
columns=fullflexible
}

\begin{document}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}{Example}[section]
\newtheorem{definition}[problem]{Definition}

\newcommand{\BEQA}{\begin{eqnarray}}
\newcommand{\EEQA}{\end{eqnarray}}
\newcommand{\define}{\stackrel{\triangle}{=}}
\bibliographystyle{IEEEtran}
\providecommand{\mbf}{\mathbf}
\providecommand{\pr}[1]{\ensuremath{\Pr\left(#1\right)}}
\providecommand{\qfunc}[1]{\ensuremath{Q\left(#1\right)}}
\providecommand{\sbrak}[1]{\ensuremath{{}\left[#1\right]}}
\providecommand{\lsbrak}[1]{\ensuremath{{}\left[#1\right.}}
\providecommand{\rsbrak}[1]{\ensuremath{{}\left.#1\right]}}
\providecommand{\brak}[1]{\ensuremath{\left(#1\right)}}
\providecommand{\lbrak}[1]{\ensuremath{\left(#1\right.}}
\providecommand{\rbrak}[1]{\ensuremath{\left.#1\right)}}
\providecommand{\cbrak}[1]{\ensuremath{\left\{#1\right\}}}
\providecommand{\lcbrak}[1]{\ensuremath{\left\{#1\right.}}
\providecommand{\rcbrak}[1]{\ensuremath{\left.#1\right\}}}
\theoremstyle{remark}
\newtheorem{rem}{Remark}
\newcommand{\sgn}{\mathop{\mathrm{sgn}}}
\providecommand{\abs}[1]{\left\vert#1\right\vert}
\providecommand{\res}[1]{\Res\displaylimits_{#1}} 
\providecommand{\norm}[1]{\left\lVert#1\right\rVert}
%\providecommand{\norm}[1]{\lVert#1\rVert}
\providecommand{\mtx}[1]{\mathbf{#1}}
\providecommand{\mean}[1]{E\left[ #1 \right]}
\providecommand{\fourier}{\overset{\mathcal{F}}{ \rightleftharpoons}}
%\providecommand{\hilbert}{\overset{\mathcal{H}}{ \rightleftharpoons}}
\providecommand{\system}{\overset{\mathcal{H}}{ \longleftrightarrow}}
	%\newcommand{\solution}[2]{\textbf{Solution:}{#1}}
\newcommand{\solution}{\noindent \textbf{Solution: }}
\newcommand{\cosec}{\,\text{cosec}\,}
\providecommand{\dec}[2]{\ensuremath{\overset{#1}{\underset{#2}{\gtrless}}}}
\newcommand{\myvec}[1]{\ensuremath{\begin{pmatrix}#1\end{pmatrix}}}
\newcommand{\mydet}[1]{\ensuremath{\begin{vmatrix}#1\end{vmatrix}}}
\numberwithin{equation}{subsection}
\makeatletter
\@addtoreset{figure}{problem}
\makeatother
\let\StandardTheFigure\thefigure
\let\vec\mathbf
\renewcommand{\thefigure}{\theproblem}
\def\putbox#1#2#3{\makebox[0in][l]{\makebox[#1][l]{}\raisebox{\baselineskip}[0in][0in]{\raisebox{#2}[0in][0in]{#3}}}}
     \def\rightbox#1{\makebox[0in][r]{#1}}
     \def\centbox#1{\makebox[0in]{#1}}
     \def\topbox#1{\raisebox{-\baselineskip}[0in][0in]{#1}}
     \def\midbox#1{\raisebox{-0.5\baselineskip}[0in][0in]{#1}}
\vspace{3cm}
\title{Matrix Theory (EE5609) Challenging Problem 2}
\author{Arkadipta De\\MTech Artificial Intelligence\\AI20MTECH14002}
\maketitle
\newpage
%\tableofcontents
\bigskip
\renewcommand{\thefigure}{\theenumi}
\renewcommand{\thetable}{\theenumi}
\begin{abstract}
This document discusses about the case when the matrix multiplication of two matrices is commutative.
\end{abstract}
Download latex codes from 
%
\begin{lstlisting}
https://github.com/Arko98/EE5609/tree/master/Challenge_2
\end{lstlisting}
%
\section{Problem}
In general, $\vec{A}\vec{B} \not= \vec{B}\vec{A}$, i.e. matrix multiplication is not commutative in general. Find the conditions for which $\vec{A}$ and $\vec{B}$ such that $\vec{A}\vec{B} = \vec{B}\vec{A}$, i.e matrix multiplication becomes commutative?
\section{Explanation}
Two matrices $\vec{A}$ and $\vec{B}$ commute on matrix multiplication if they are simultaneously diagonalizable that means if both of them can be diagonalized simultaneously.\\
An square matrix of order $n$, $\vec{A}$ is diagonalizable if and only if it has $n$ linearly independent eigen vectors, which is similar to a diagonal matrix and can be expressed as follows,
\begin{align}\label{eq1}
    \vec{A} = \vec{P}\vec{D_1}\vec{P}^{-1}
\end{align}
For an invertible matrix $\vec{P}$ and a diagonal matrix $\vec{D_1}$. The columns of $\vec{P}$ are nothing but $n$ linearly independent eigen vectors of $\vec{A}$, and the diagonal elements of the matrix $\vec{D_1}$ are eigenvalues of $\vec{A}$ that correspond to respective eigen vectors in $\vec{P}$\\
Another $n$ order square matrix $\vec{B}$ is said to be simultaneously diagonalizable with the matrix $\vec{A}$ if the same invertible matrix $\vec{P}$ also diagonalizes matrix $\vec{B}$. Hence, $\vec{B}$ can be expressed as follows
\begin{align}\label{eq2}
    \vec{B} = \vec{P}\vec{D_2}\vec{P}^{-1}
\end{align}
\section{Explanation}
If two $n$ sized square matrix are simultaneously diagonalizable by the same invertible matrix $\vec{P}$, then $\vec{A}\vec{B}$ can be expressed as follows,
\begin{align}
\vec{A}\vec{B} & = (\vec{P}\vec{D_1}\vec{P}^{-1})(\vec{P}\vec{D_2}\vec{P}^{-1})\\
\implies\vec{A}\vec{B}&=\vec{P}\vec{D_1}(\vec{P}^{-1}\vec{P})\vec{D_2}\vec{P}^{-1}\\
\implies\vec{A}\vec{B}&=\vec{P}\vec{D_1}\vec{D_2}\vec{P}^{-1}\label{eq3}
\end{align}
Again, $\vec{B}\vec{A}$ can be expressed as follows,
\begin{align}
\vec{B}\vec{A} & = (\vec{P}\vec{D_2}\vec{P}^{-1})(\vec{P}\vec{D_1}\vec{P}^{-1})\\
\implies\vec{B}\vec{A}&=\vec{P}\vec{D_2}(\vec{P}^{-1}\vec{P})\vec{D_1}\vec{P}^{-1}\\
\implies\vec{B}\vec{A}&=\vec{P}\vec{D_2}\vec{D_1}\vec{P}^{-1}\label{eq4}
\end{align}
Since the two matrices, $\vec{D_1}$ and $\vec{D_2}$ are diagonal matrices, the product of these diagonal matrices is the product of their corresponding diagonal elements. Multiplication for the diagonal elements is commutative since the result of multiplication is scalar. Hence,
\begin{align}
\vec{D_1}\vec{D_2} = \vec{D_2}\vec{D_1}\label{eq5}
\end{align}
Hence from equations \eqref{eq3},\eqref{eq4} and \eqref{eq5},
\begin{align}
\vec{A}\vec{B} = \vec{B}\vec{A}
\end{align}
Hence, proved that, when two $n$ order square matrices are simultaneously diagonalizable then, the matrix multiplication is commutative.
\end{document}